initSidebarItems({"fn":[["_cls_u32","Counts the leading most significant bits set."],["_cls_u64","Counts the leading most significant bits set."],["_clz_u16","Count Leading Zeros."],["_clz_u32","Count Leading Zeros."],["_clz_u64","Count Leading Zeros."],["_clz_u8","Count Leading Zeros."],["_rbit_u32","Reverse the bit order."],["_rbit_u64","Reverse the bit order."],["_rev_u16","Reverse the order of the bytes."],["_rev_u16","Reverse the order of the bytes."],["_rev_u32","Reverse the order of the bytes."],["_rev_u32","Reverse the order of the bytes."],["_rev_u64","Reverse the order of the bytes."],["vadd_f32","Vector add."],["vadd_f64","Vector add."],["vadd_s16","Vector add."],["vadd_s32","Vector add."],["vadd_s8","Vector add."],["vadd_u16","Vector add."],["vadd_u32","Vector add."],["vadd_u8","Vector add."],["vaddd_s64","Vector add."],["vaddd_u64","Vector add."],["vaddl_s16","Vector long add."],["vaddl_s32","Vector long add."],["vaddl_s8","Vector long add."],["vaddl_u16","Vector long add."],["vaddl_u32","Vector long add."],["vaddl_u8","Vector long add."],["vaddq_f32","Vector add."],["vaddq_f64","Vector add."],["vaddq_s16","Vector add."],["vaddq_s32","Vector add."],["vaddq_s64","Vector add."],["vaddq_s8","Vector add."],["vaddq_u16","Vector add."],["vaddq_u32","Vector add."],["vaddq_u64","Vector add."],["vaddq_u8","Vector add."],["vaesdq_u8","AES single round decryption."],["vaeseq_u8","AES single round encryption."],["vaesimcq_u8","AES inverse mix columns."],["vaesmcq_u8","AES mix columns."],["vmaxv_f32","Horizontal vector max."],["vmaxv_s16","Horizontal vector max."],["vmaxv_s32","Horizontal vector max."],["vmaxv_s8","Horizontal vector max."],["vmaxv_u16","Horizontal vector max."],["vmaxv_u32","Horizontal vector max."],["vmaxv_u8","Horizontal vector max."],["vmaxvq_f32","Horizontal vector max."],["vmaxvq_f64","Horizontal vector max."],["vmaxvq_s16","Horizontal vector max."],["vmaxvq_s32","Horizontal vector max."],["vmaxvq_s8","Horizontal vector max."],["vmaxvq_u16","Horizontal vector max."],["vmaxvq_u32","Horizontal vector max."],["vmaxvq_u8","Horizontal vector max."],["vminv_f32","Horizontal vector min."],["vminv_s16","Horizontal vector min."],["vminv_s32","Horizontal vector min."],["vminv_s8","Horizontal vector min."],["vminv_u16","Horizontal vector min."],["vminv_u32","Horizontal vector min."],["vminv_u8","Horizontal vector min."],["vminvq_f32","Horizontal vector min."],["vminvq_f64","Horizontal vector min."],["vminvq_s16","Horizontal vector min."],["vminvq_s32","Horizontal vector min."],["vminvq_s8","Horizontal vector min."],["vminvq_u16","Horizontal vector min."],["vminvq_u32","Horizontal vector min."],["vminvq_u8","Horizontal vector min."],["vmovl_s16","Vector long move."],["vmovl_s32","Vector long move."],["vmovl_s8","Vector long move."],["vmovl_u16","Vector long move."],["vmovl_u32","Vector long move."],["vmovl_u8","Vector long move."],["vmovn_s16","Vector narrow integer."],["vmovn_s32","Vector narrow integer."],["vmovn_s64","Vector narrow integer."],["vmovn_u16","Vector narrow integer."],["vmovn_u32","Vector narrow integer."],["vmovn_u64","Vector narrow integer."],["vpmax_f32","Folding maximum of adjacent pairs"],["vpmax_s16","Folding maximum of adjacent pairs"],["vpmax_s32","Folding maximum of adjacent pairs"],["vpmax_s8","Folding maximum of adjacent pairs"],["vpmax_u16","Folding maximum of adjacent pairs"],["vpmax_u32","Folding maximum of adjacent pairs"],["vpmax_u8","Folding maximum of adjacent pairs"],["vpmaxq_f32","Folding maximum of adjacent pairs"],["vpmaxq_f64","Folding maximum of adjacent pairs"],["vpmaxq_s16","Folding maximum of adjacent pairs"],["vpmaxq_s32","Folding maximum of adjacent pairs"],["vpmaxq_s8","Folding maximum of adjacent pairs"],["vpmaxq_u16","Folding maximum of adjacent pairs"],["vpmaxq_u32","Folding maximum of adjacent pairs"],["vpmaxq_u8","Folding maximum of adjacent pairs"],["vpmin_f32","Folding minimum of adjacent pairs"],["vpmin_s16","Folding minimum of adjacent pairs"],["vpmin_s32","Folding minimum of adjacent pairs"],["vpmin_s8","Folding minimum of adjacent pairs"],["vpmin_u16","Folding minimum of adjacent pairs"],["vpmin_u32","Folding minimum of adjacent pairs"],["vpmin_u8","Folding minimum of adjacent pairs"],["vpminq_f32","Folding minimum of adjacent pairs"],["vpminq_f64","Folding minimum of adjacent pairs"],["vpminq_s16","Folding minimum of adjacent pairs"],["vpminq_s32","Folding minimum of adjacent pairs"],["vpminq_s8","Folding minimum of adjacent pairs"],["vpminq_u16","Folding minimum of adjacent pairs"],["vpminq_u32","Folding minimum of adjacent pairs"],["vpminq_u8","Folding minimum of adjacent pairs"],["vrsqrte_f32","Reciprocal square-root estimate."],["vsha1cq_u32","SHA1 hash update accelerator, choose."],["vsha1h_u32","SHA1 fixed rotate."],["vsha1mq_u32","SHA1 hash update accelerator, majority."],["vsha1pq_u32","SHA1 hash update accelerator, parity."],["vsha1su0q_u32","SHA1 schedule update accelerator, first part."],["vsha1su1q_u32","SHA1 schedule update accelerator, second part."],["vsha256h2q_u32","SHA256 hash update accelerator, upper part."],["vsha256hq_u32","SHA256 hash update accelerator."],["vsha256su0q_u32","SHA256 schedule update accelerator, first part."],["vsha256su1q_u32","SHA256 schedule update accelerator, second part."]],"struct":[["float32x2_t","ARM-specific 64-bit wide vector of two packed `f32`."],["float32x4_t","ARM-specific 128-bit wide vector of four packed `f32`."],["float64x1_t","ARM-specific 64-bit wide vector of one packed `f64`."],["float64x2_t","ARM-specific 128-bit wide vector of two packed `f64`."],["int16x4_t","ARM-specific 64-bit wide vector of four packed `i16`."],["int16x8_t","ARM-specific 128-bit wide vector of eight packed `i16`."],["int32x2_t","ARM-specific 64-bit wide vector of two packed `i32`."],["int32x4_t","ARM-specific 128-bit wide vector of four packed `i32`."],["int64x1_t","ARM-specific 64-bit wide vector of one packed `i64`."],["int64x2_t","ARM-specific 128-bit wide vector of two packed `i64`."],["int8x16_t","ARM-specific 128-bit wide vector of sixteen packed `i8`."],["int8x8_t","ARM-specific 64-bit wide vector of eight packed `i8`."],["poly16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["poly16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["poly8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["poly8x8_t","ARM-specific 64-bit wide polynomial vector of eight packed `u8`."],["uint16x4_t","ARM-specific 64-bit wide vector of four packed `u16`."],["uint16x8_t","ARM-specific 128-bit wide vector of eight packed `u16`."],["uint32x2_t","ARM-specific 64-bit wide vector of two packed `u32`."],["uint32x4_t","ARM-specific 128-bit wide vector of four packed `u32`."],["uint64x1_t","ARM-specific 64-bit wide vector of one packed `u64`."],["uint64x2_t","ARM-specific 128-bit wide vector of two packed `u64`."],["uint8x16_t","ARM-specific 128-bit wide vector of sixteen packed `u8`."],["uint8x8_t","ARM-specific 64-bit wide vector of eight packed `u8`."]]});